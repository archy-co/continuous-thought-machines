{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de29679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../continuous-thought-machines_mine\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import mediapy\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from data.custom_datasets import ImageNet\n",
    "from tasks.image_classification.imagenet_classes import IMAGENET2012_CLASSES\n",
    "\n",
    "\n",
    "import argparse\n",
    "from torchvision import transforms\n",
    "from models.ctm import ContinuousThoughtMachine as CTM\n",
    "from data.custom_datasets import KanjiMeaning_singleLabel\n",
    "from utils.schedulers import WarmupCosineAnnealingLR, WarmupMultiStepLR, warmup\n",
    "from tasks.image_classification.plotting import plot_neural_dynamics, make_classification_gif\n",
    "from utils.losses import image_classification_loss\n",
    "\n",
    "from utils.housekeeping import save_dict_to_csv, get_meaning, get_number, load_dict_from_csv\n",
    "\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26cd09",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b5ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor_and_device(data, device):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return data.to(device)\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        return torch.tensor(data).to(device)\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return torch.from_numpy(data).to(device)\n",
    "    else:\n",
    "        return torch.tensor(data).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c07b5c",
   "metadata": {},
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc83e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e053fd",
   "metadata": {},
   "source": [
    "### parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005a73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model Selection\n",
    "    parser.add_argument('--model', type=str, default='ctm', choices=['ctm', 'lstm', 'ff'], help='Model type to train.')\n",
    "\n",
    "    # Model Architecture\n",
    "    # Common\n",
    "    parser.add_argument('--d_model', type=int, default=512, help='Dimension of the model.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.0, help='Dropout rate.')\n",
    "    parser.add_argument('--backbone_type', type=str, default='resnet18-4', help='Type of backbone featureiser.')\n",
    "    # CTM / LSTM specific\n",
    "    parser.add_argument('--d_input', type=int, default=128, help='Dimension of the input (CTM, LSTM).')\n",
    "    parser.add_argument('--heads', type=int, default=4, help='Number of attention heads (CTM, LSTM).')\n",
    "    parser.add_argument('--iterations', type=int, default=75, help='Number of internal ticks (CTM, LSTM).')\n",
    "    parser.add_argument('--positional_embedding_type', type=str, default='none', help='Type of positional embedding (CTM, LSTM).',\n",
    "                        choices=['none',\n",
    "                                 'learnable-fourier',\n",
    "                                 'multi-learnable-fourier',\n",
    "                                 'custom-rotational'])\n",
    "    # CTM specific\n",
    "    parser.add_argument('--synapse_depth', type=int, default=4, help='Depth of U-NET model for synapse. 1=linear, no unet (CTM only).')\n",
    "    parser.add_argument('--n_synch_out', type=int, default=512, help='Number of neurons to use for output synch (CTM only).')\n",
    "    parser.add_argument('--n_synch_action', type=int, default=512, help='Number of neurons to use for observation/action synch (CTM only).')\n",
    "    parser.add_argument('--neuron_select_type', type=str, default='random-pairing', help='Protocol for selecting neuron subset (CTM only).')\n",
    "    parser.add_argument('--n_random_pairing_self', type=int, default=0, help='Number of neurons paired self-to-self for synch (CTM only).')\n",
    "    parser.add_argument('--memory_length', type=int, default=25, help='Length of the pre-activation history for NLMS (CTM only).')\n",
    "    parser.add_argument('--deep_memory', action=argparse.BooleanOptionalAction, default=True, help='Use deep memory (CTM only).')\n",
    "    parser.add_argument('--memory_hidden_dims', type=int, default=4, help='Hidden dimensions of the memory if using deep memory (CTM only).')\n",
    "    parser.add_argument('--dropout_nlm', type=float, default=None, help='Dropout rate for NLMs specifically. Unset to match dropout on the rest of the model (CTM only).')\n",
    "    parser.add_argument('--do_normalisation', action=argparse.BooleanOptionalAction, default=False, help='Apply normalization in NLMs (CTM only).')\n",
    "    # LSTM specific\n",
    "    parser.add_argument('--num_layers', type=int, default=2, help='Number of LSTM stacked layers (LSTM only).')\n",
    "\n",
    "    # Training\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training.')\n",
    "    parser.add_argument('--batch_size_test', type=int, default=32, help='Batch size for testing.')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate for the model.')\n",
    "    parser.add_argument('--training_iterations', type=int, default=100001, help='Number of training iterations.')\n",
    "    parser.add_argument('--warmup_steps', type=int, default=5000, help='Number of warmup steps.')\n",
    "    parser.add_argument('--use_scheduler', action=argparse.BooleanOptionalAction, default=True, help='Use a learning rate scheduler.')\n",
    "    parser.add_argument('--scheduler_type', type=str, default='cosine', choices=['multistep', 'cosine'], help='Type of learning rate scheduler.')\n",
    "    parser.add_argument('--milestones', type=int, default=[8000, 15000, 20000], nargs='+', help='Learning rate scheduler milestones.')\n",
    "    parser.add_argument('--gamma', type=float, default=0.1, help='Learning rate scheduler gamma for multistep.')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0, help='Weight decay factor.')\n",
    "    parser.add_argument('--weight_decay_exclusion_list', type=str, nargs='+', default=[], help='List to exclude from weight decay. Typically good: bn, ln, bias, start')\n",
    "    parser.add_argument('--gradient_clipping', type=float, default=-1, help='Gradient quantile clipping value (-1 to disable).')\n",
    "    parser.add_argument('--do_compile', action=argparse.BooleanOptionalAction, default=False, help='Try to compile model components (backbone, synapses if CTM).')\n",
    "    parser.add_argument('--num_workers_train', type=int, default=1, help='Num workers training.')\n",
    "    parser.add_argument('--num_workers_test', type=int, default=1, help='Num workers test.')\n",
    "\n",
    "    # Housekeeping\n",
    "    parser.add_argument('--log_dir', type=str, default='logs/scratch', help='Directory for logging.')\n",
    "    parser.add_argument('--dataset', type=str, default='cifar10', help='Dataset to use.')\n",
    "    parser.add_argument('--data_root', type=str, default='data/', help='Where to save dataset.')\n",
    "    parser.add_argument('--save_every', type=int, default=1000, help='Save checkpoints every this many iterations.')\n",
    "    parser.add_argument('--seed', type=int, default=412, help='Random seed.')\n",
    "    parser.add_argument('--reload', action=argparse.BooleanOptionalAction, default=False, help='Reload from disk?')\n",
    "    parser.add_argument('--reload_model_only', action=argparse.BooleanOptionalAction, default=False, help='Reload only the model from disk?')\n",
    "    parser.add_argument('--strict_reload', action=argparse.BooleanOptionalAction, default=True, help='Should use strict reload for model weights.') # Added back\n",
    "    parser.add_argument('--track_every', type=int, default=1000, help='Track metrics every this many iterations.')\n",
    "    parser.add_argument('--n_test_batches', type=int, default=20, help='How many minibatches to approx metrics. Set to -1 for full eval')\n",
    "    parser.add_argument('--device', type=int, nargs='+', default=[0], help='List of GPU(s) to use. Set to -1 to use CPU.')\n",
    "    parser.add_argument('--use_amp', action=argparse.BooleanOptionalAction, default=False, help='AMP autocast.')\n",
    "\n",
    "    \n",
    "    parser.add_argument('--isGrayscale', action=argparse.BooleanOptionalAction, default=False, help='Is dataset grayscale or RGB? (default: RGB (isGrayscale = False)')\n",
    "    parser.add_argument('--f', type=str, default='dummy', help='Dummy (required to run from .ipynb)')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760e752",
   "metadata": {},
   "source": [
    "### get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53731a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset, root, isGrayscale=False):\n",
    "    if dataset=='imagenet':\n",
    "        dataset_mean = [0.485, 0.456, 0.406]\n",
    "        dataset_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        normalize = transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "\n",
    "        class_labels = list(IMAGENET2012_CLASSES.values())\n",
    "\n",
    "        train_data = ImageNet(which_split='train', transform=train_transform)\n",
    "        test_data = ImageNet(which_split='validation', transform=test_transform)\n",
    "    elif dataset=='kanji':\n",
    "        if isGrayscale:\n",
    "            dataset_mean = [0.5]  # Single channel grayscale\n",
    "            dataset_std = [0.5]   # Maps [0,1] to [-1,1]\n",
    "        else:\n",
    "            dataset_mean = [0.485, 0.456, 0.406]\n",
    "            dataset_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        normalize = transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "        \n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomRotation(degrees=5),\n",
    "            # transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "        \n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "        \n",
    "        full_dataset = KanjiMeaning_singleLabel(os.path.join(root, \"train\"), transform=None)\n",
    "        all_prompts = full_dataset.get_prompts()\n",
    "        class_labels = sorted(list(set(all_prompts)))  # Unique prompts as class labels\n",
    "        \n",
    "        \n",
    "        train_data = KanjiMeaning_singleLabel(os.path.join(root, \"train\"), transform=train_transform, isGrayscale=isGrayscale)\n",
    "        test_data = KanjiMeaning_singleLabel(os.path.join(root, \"test\"), transform=test_transform, isGrayscale=isGrayscale)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return train_data, test_data, class_labels, dataset_mean, dataset_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2a043",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591d791",
   "metadata": {},
   "source": [
    "###### For Kanji_test5_updatedDataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ae14a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model ctm on cuda:0\n"
     ]
    }
   ],
   "source": [
    "prompt_idx_fn = 'prompt_index.csv'\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "args.log_dir = \"Kanji_test5_updDS1_heads4\"\n",
    "args.dataset = \"kanji\"\n",
    "args.save_every = 500\n",
    "args.warmup_steps = 3000\n",
    "args.d_model = 256\n",
    "args.reload = True\n",
    "checkpoint_path = os.path.join(args.log_dir, \"checkpoint_10000.pt\")\n",
    "args.training_iterations = 20001\n",
    "args.heads = 4\n",
    "args.track_every = 1000\n",
    "\n",
    "args.isGrayscale = False\n",
    "\n",
    "loss_func = image_classification_loss\n",
    "\n",
    "\n",
    "if args.device[0] != -1:\n",
    "    device = f'cuda:{args.device[0]}'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Running model {args.model} on {device}')\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039fe71",
   "metadata": {},
   "source": [
    "###### For Kanji_test6_updDS1_b&w_heads8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e09da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model ctm on cuda:0\n"
     ]
    }
   ],
   "source": [
    "prompt_idx_fn = 'prompt_index.csv'\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "args.log_dir = \"Kanji_test6_updDS1_b&w_heads8\"\n",
    "args.dataset = \"kanji\"\n",
    "args.reload = True\n",
    "checkpoint_path = os.path.join(args.log_dir, \"checkpoint_3000.pt\")\n",
    "\n",
    "args.save_every = 500\n",
    "args.track_every = 1000\n",
    "args.warmup_steps = 3000\n",
    "args.training_iterations = 20001\n",
    "\n",
    "args.d_model = 256\n",
    "args.heads = 8\n",
    "\n",
    "args.isGrayscale = True\n",
    "\n",
    "\n",
    "if args.device[0] != -1:\n",
    "    device = f'cuda:{args.device[0]}'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Running model {args.model} on {device}')\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481c95d",
   "metadata": {},
   "source": [
    "###### Kanji_test7_updDS1_heads8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a38cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model ctm on cuda:0\n"
     ]
    }
   ],
   "source": [
    "prompt_idx_fn = 'prompt_index.csv'\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "args.log_dir = \"Kanji_test7_updDS1_heads8\"\n",
    "args.dataset = \"kanji\"\n",
    "args.reload = True\n",
    "checkpoint_path = os.path.join(args.log_dir, \"checkpoint_12500.pt\")\n",
    "\n",
    "args.save_every = 500\n",
    "args.track_every = 1000\n",
    "args.warmup_steps = 3000\n",
    "args.training_iterations = 20001\n",
    "\n",
    "args.d_model = 256\n",
    "args.heads = 8\n",
    "\n",
    "args.isGrayscale = False\n",
    "\n",
    "\n",
    "if args.device[0] != -1:\n",
    "    device = f'cuda:{args.device[0]}'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Running model {args.model} on {device}')\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62eb51b",
   "metadata": {},
   "source": [
    "##### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7ddf00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model ctm on cuda:0\n"
     ]
    }
   ],
   "source": [
    "prompt_idx_fn = 'prompt_index.csv'\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "args.log_dir = \"Kanji_test5_updDS1_heads4\"\n",
    "args.dataset = \"kanji\"\n",
    "args.save_every = 500\n",
    "args.warmup_steps = 3000\n",
    "args.d_model = 256\n",
    "args.reload = True\n",
    "checkpoint_path = os.path.join(args.log_dir, \"checkpoint_10000.pt\")\n",
    "args.training_iterations = 20001\n",
    "args.heads = 4\n",
    "args.track_every = 1000\n",
    "\n",
    "args.isGrayscale = False\n",
    "\n",
    "loss_func = image_classification_loss\n",
    "\n",
    "\n",
    "if args.device[0] != -1:\n",
    "    device = f'cuda:{args.device[0]}'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Running model {args.model} on {device}')\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039d7d1",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "214bbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kanji_collate_fn(batch):\n",
    "    images, prompts = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    return images, list(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f80cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29025 Kanji samples from ./Kanji/train\n",
      "Loaded 29025 Kanji samples from ./Kanji/train\n",
      "Loaded 22 Kanji samples from ./Kanji/test\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, class_labels, dataset_mean, dataset_std = get_dataset('kanji', './Kanji', args.isGrayscale)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers_train, collate_fn=kanji_collate_fn)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size_test, shuffle=True, num_workers=args.num_workers_test, drop_last=False, collate_fn=kanji_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd3ca3",
   "metadata": {},
   "source": [
    "### Prompt-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fec0fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Prompt-index csv file <prompt_index.csv> already exists, not overwriting it. If you want to refresh it, delete it first.\n"
     ]
    }
   ],
   "source": [
    "prompt_to_idx = {prompt: idx for idx, prompt in enumerate(class_labels)}\n",
    "\n",
    "args.out_dims = len(class_labels)\n",
    "prediction_reshaper = [-1]\n",
    "\n",
    "if not os.path.exists(prompt_idx_fn):\n",
    "    print(f\"Saving prompt-index csv as <{prompt_idx_fn}>\")\n",
    "    save_dict_to_csv(prompt_to_idx, prompt_idx_fn)\n",
    "else:\n",
    "    print(f\"INFO: Prompt-index csv file <{prompt_idx_fn}> already exists, not overwriting it. If you want to refresh it, delete it first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165fa9e",
   "metadata": {},
   "source": [
    "###### Test prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "861588f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 1 means: Japan\n",
      "'Kanji for (god of) drought' is number: None\n",
      "Number 999 means: besiege\n",
      "'Non-existent' is number: None\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "print(\"Number 1 means:\", get_meaning(111, prompt_to_idx))\n",
    "print(\"'Kanji for (god of) drought' is number:\", get_number('Kanji for (god of) drought', prompt_to_idx))\n",
    "\n",
    "# Test with non-existent values\n",
    "print(\"Number 999 means:\", get_meaning(999, prompt_to_idx))\n",
    "print(\"'Non-existent' is number:\", get_number('Non-existent', prompt_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f88271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8657 entries from prompt_index.csv\n",
      "Number 1 means: Italy\n",
      "'Kanji for (god of) drought' is number: None\n",
      "Number 999 means: besides\n",
      "'Non-existent' is number: None\n"
     ]
    }
   ],
   "source": [
    "prompt_to_idx_loaded = load_dict_from_csv(prompt_idx_fn)\n",
    "\n",
    "# Test the functions\n",
    "print(\"Number 1 means:\", get_meaning(111, prompt_to_idx_loaded))\n",
    "print(\"'Kanji for (god of) drought' is number:\", get_number('Kanji for (god of) drought', prompt_to_idx_loaded))\n",
    "\n",
    "# Test with non-existent values\n",
    "print(\"Number 999 means:\", get_meaning(999, prompt_to_idx_loaded))\n",
    "print(\"'Non-existent' is number:\", get_number('Non-existent', prompt_to_idx_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c13559",
   "metadata": {},
   "source": [
    "### Initialize model etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed3d0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using neuron select type: random-pairing\n",
      "Synch representation size action: 512\n",
      "Synch representation size out: 512\n"
     ]
    }
   ],
   "source": [
    "model = CTM(\n",
    "    iterations=args.iterations,\n",
    "    d_model=args.d_model,\n",
    "    d_input=args.d_input,\n",
    "    heads=args.heads,\n",
    "    n_synch_out=args.n_synch_out,\n",
    "    n_synch_action=args.n_synch_action,\n",
    "    synapse_depth=args.synapse_depth,\n",
    "    memory_length=args.memory_length,\n",
    "    deep_nlms=args.deep_memory,\n",
    "    memory_hidden_dims=args.memory_hidden_dims,\n",
    "    do_layernorm_nlm=args.do_normalisation,\n",
    "    backbone_type=args.backbone_type,\n",
    "    positional_embedding_type=args.positional_embedding_type,\n",
    "    out_dims=args.out_dims,\n",
    "    prediction_reshaper=prediction_reshaper,\n",
    "    dropout=args.dropout,\n",
    "    dropout_nlm=args.dropout_nlm,\n",
    "    neuron_select_type=args.neuron_select_type,\n",
    "    n_random_pairing_self=args.n_random_pairing_self,\n",
    "    isGrayscale=args.isGrayscale\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb29c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 16100046\n"
     ]
    }
   ],
   "source": [
    "# For lazy modules so that we can get param count\n",
    "pseudo_inputs = train_data.__getitem__(0)[0].unsqueeze(0).to(device)\n",
    "model(pseudo_inputs)\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "print(f'Total params: {sum(p.numel() for p in model.parameters())}')\n",
    "decay_params = []\n",
    "no_decay_params = []\n",
    "no_decay_names = []\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        continue # Skip parameters that don't require gradients\n",
    "    if any(exclusion_str in name for exclusion_str in args.weight_decay_exclusion_list):\n",
    "        no_decay_params.append(param)\n",
    "        no_decay_names.append(name)\n",
    "    else:\n",
    "        decay_params.append(param)\n",
    "if len(no_decay_names):\n",
    "    print(f'WARNING, excluding: {no_decay_names}')\n",
    "\n",
    "# Optimizer and scheduler (Common setup)\n",
    "if len(no_decay_names) and args.weight_decay!=0:\n",
    "    optimizer = torch.optim.AdamW([{'params': decay_params, 'weight_decay':args.weight_decay},\n",
    "                                    {'params': no_decay_params, 'weight_decay':0}],\n",
    "                                lr=args.lr,\n",
    "                                eps=1e-8 if not args.use_amp else 1e-6)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                lr=args.lr,\n",
    "                                eps=1e-8 if not args.use_amp else 1e-6,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "\n",
    "warmup_schedule = warmup(args.warmup_steps)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_schedule.step)\n",
    "if args.use_scheduler:\n",
    "    if args.scheduler_type == 'multistep':\n",
    "        scheduler = WarmupMultiStepLR(optimizer, warmup_steps=args.warmup_steps, milestones=args.milestones, gamma=args.gamma)\n",
    "    elif args.scheduler_type == 'cosine':\n",
    "        scheduler = WarmupCosineAnnealingLR(optimizer, args.warmup_steps, args.training_iterations, warmup_start_lr=1e-20, eta_min=1e-7)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6895cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics tracking\n",
    "start_iter = 0\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "iters = []\n",
    "# Conditional metrics for CTM/LSTM\n",
    "train_accuracies_most_certain = [] if args.model in ['ctm', 'lstm'] else None\n",
    "test_accuracies_most_certain = [] if args.model in ['ctm', 'lstm'] else None\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\" if \"cuda\" in device else \"cpu\", enabled=args.use_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e432aa",
   "metadata": {},
   "source": [
    "### Reloading logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a0a3d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading from: Kanji_test5_updDS1_heads4/checkpoint_10000.pt\n",
      " Loaded state_dict. Missing: [], Unexpected: []\n",
      "Reloading optimizer etc.\n"
     ]
    }
   ],
   "source": [
    "if args.reload:\n",
    "    # checkpoint_path = f'{args.log_dir}/checkpoint_250.pt'\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f'Reloading from: {checkpoint_path}')\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        if not args.strict_reload: print('WARNING: not using strict reload for model weights!')\n",
    "        load_result = model.load_state_dict(checkpoint['model_state_dict'], strict=args.strict_reload)\n",
    "        print(f\" Loaded state_dict. Missing: {load_result.missing_keys}, Unexpected: {load_result.unexpected_keys}\")\n",
    "\n",
    "        if not args.reload_model_only:\n",
    "            print('Reloading optimizer etc.')\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "            start_iter = checkpoint['iteration']\n",
    "            # Load common metrics\n",
    "            train_losses = checkpoint['train_losses']\n",
    "            test_losses = checkpoint['test_losses']\n",
    "            train_accuracies = checkpoint['train_accuracies'] \n",
    "            test_accuracies = checkpoint['test_accuracies'] \n",
    "            iters = checkpoint['iters']\n",
    "\n",
    "            # Load conditional metrics if they exist in checkpoint and are expected for current model\n",
    "            if args.model in ['ctm', 'lstm']:\n",
    "                train_accuracies_most_certain = checkpoint['train_accuracies_most_certain']\n",
    "                test_accuracies_most_certain = checkpoint['test_accuracies_most_certain']\n",
    "\n",
    "        else:\n",
    "            print('Only reloading model!')\n",
    "\n",
    "        if 'torch_rng_state' in checkpoint:\n",
    "            # Reset seeds\n",
    "            torch.set_rng_state(checkpoint['torch_rng_state'].cpu().byte())\n",
    "            np.random.set_state(checkpoint['numpy_rng_state'])\n",
    "            random.setstate(checkpoint['random_rng_state'])\n",
    "\n",
    "        del checkpoint\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9265694",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc30d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(trainloader)\n",
    "\n",
    "with tqdm(total=args.training_iterations, initial=start_iter, leave=False, position=0, dynamic_ncols=True) as pbar:\n",
    "    for bi in range(start_iter, args.training_iterations):\n",
    "        if bi % 100 == 0:\n",
    "            print(f\"{bi}/{args.training_iterations}\")\n",
    "\n",
    "        current_lr = optimizer.param_groups[-1]['lr']\n",
    "\n",
    "        try:\n",
    "            inputs, targets = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(trainloader)\n",
    "            inputs, targets = next(iterator)\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        target_indices = [prompt_to_idx.get(prompt, 0) for prompt in targets]\n",
    "        targets = torch.tensor(target_indices, dtype=torch.long).to(device)\n",
    "\n",
    "        loss = None\n",
    "        accuracy = None\n",
    "        # Model-specific forward and loss calculation\n",
    "        with torch.autocast(device_type=\"cuda\" if \"cuda\" in device else \"cpu\", dtype=torch.float16, enabled=args.use_amp):\n",
    "            if args.do_compile: # CUDAGraph marking for clean compile\n",
    "                    torch.compiler.cudagraph_mark_step_begin()\n",
    "\n",
    "            if args.model == 'ctm':\n",
    "                predictions, certainties, synchronisation = model(inputs)\n",
    "                loss, where_most_certain = loss_func(predictions, certainties, targets, use_most_certain=True)\n",
    "                accuracy = (predictions.argmax(1)[torch.arange(predictions.size(0), device=predictions.device),where_most_certain] == targets).float().mean().item()\n",
    "                pbar_desc = f'CTM Loss={loss.item():0.3f}. Acc={accuracy:0.3f}. LR={current_lr:0.6f}. Where_certain={where_most_certain.float().mean().item():0.2f}+-{where_most_certain.float().std().item():0.2f} ({where_most_certain.min().item():d}<->{where_most_certain.max().item():d})'\n",
    "\n",
    "            elif args.model == 'lstm':\n",
    "                predictions, certainties, synchronisation = model(inputs)\n",
    "                loss, where_most_certain = loss_func(predictions, certainties, targets, use_most_certain=True)\n",
    "                # LSTM where_most_certain will just be -1 because use_most_certain is False owing to stability issues with LSTM training\n",
    "                accuracy = (predictions.argmax(1)[torch.arange(predictions.size(0), device=predictions.device),where_most_certain] == targets).float().mean().item()\n",
    "                pbar_desc = f'LSTM Loss={loss.item():0.3f}. Acc={accuracy:0.3f}. LR={current_lr:0.6f}. Where_certain={where_most_certain.float().mean().item():0.2f}+-{where_most_certain.float().std().item():0.2f} ({where_most_certain.min().item():d}<->{where_most_certain.max().item():d})'\n",
    "\n",
    "            elif args.model == 'ff':\n",
    "                predictions = model(inputs)\n",
    "                loss = nn.CrossEntropyLoss()(predictions, targets)\n",
    "                accuracy = (predictions.argmax(1) == targets).float().mean().item()\n",
    "                pbar_desc = f'FF Loss={loss.item():0.3f}. Acc={accuracy:0.3f}. LR={current_lr:0.6f}'\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if args.gradient_clipping!=-1:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.gradient_clipping)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "        pbar.set_description(f'Dataset={args.dataset}. Model={args.model}. {pbar_desc}')\n",
    "\n",
    "\n",
    "        # Metrics tracking and plotting (conditional logic needed)\n",
    "        if (bi % args.track_every == 0 or bi == args.warmup_steps) and (bi != 0 or args.reload_model_only):\n",
    "\n",
    "            iters.append(bi)\n",
    "            current_train_losses = []\n",
    "            current_test_losses = []\n",
    "            current_train_accuracies = [] # Holds list of accuracies per tick for CTM/LSTM, single value for FF\n",
    "            current_test_accuracies = [] # Holds list of accuracies per tick for CTM/LSTM, single value for FF\n",
    "            current_train_accuracies_most_certain = [] # Only for CTM/LSTM\n",
    "            current_test_accuracies_most_certain = [] # Only for CTM/LSTM\n",
    "\n",
    "\n",
    "            # Reset BN stats using train mode\n",
    "            pbar.set_description('Resetting BN')\n",
    "            model.train()\n",
    "            for module in model.modules():\n",
    "                if isinstance(module, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)):\n",
    "                    module.reset_running_stats()\n",
    "\n",
    "            pbar.set_description('Tracking: Computing TRAIN metrics')\n",
    "            with torch.no_grad(): # Should use inference_mode? CTM/LSTM scripts used no_grad\n",
    "                loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size_test, shuffle=True, num_workers=args.num_workers_test, collate_fn=kanji_collate_fn)\n",
    "                all_targets_list = []\n",
    "                all_predictions_list = [] # List to store raw predictions (B, C, T) or (B, C)\n",
    "                all_predictions_most_certain_list = [] # Only for CTM/LSTM\n",
    "                all_losses = []\n",
    "\n",
    "                with tqdm(total=len(loader), initial=0, leave=False, position=1, dynamic_ncols=True) as pbar_inner:\n",
    "                    for inferi, (inputs, targets) in enumerate(loader):\n",
    "                        inputs = inputs.to(device)\n",
    "                        \n",
    "                        target_indices = [prompt_to_idx.get(prompt, 0) for prompt in targets]\n",
    "                        targets = torch.tensor(target_indices, dtype=torch.long).to(device)\n",
    "\n",
    "                        all_targets_list.append(targets.detach().cpu().numpy())\n",
    "\n",
    "                        # Model-specific forward and loss for evaluation\n",
    "                        if args.model == 'ctm':\n",
    "                            these_predictions, certainties, _ = model(inputs)\n",
    "                            loss, where_most_certain = loss_func(these_predictions, certainties, targets, use_most_certain=True)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy()) # Shape (B, T)\n",
    "                            all_predictions_most_certain_list.append(these_predictions.argmax(1)[torch.arange(these_predictions.size(0), device=these_predictions.device), where_most_certain].detach().cpu().numpy()) # Shape (B,)\n",
    "\n",
    "                        elif args.model == 'lstm':\n",
    "                            these_predictions, certainties, _ = model(inputs)\n",
    "                            loss, where_most_certain = loss_func(these_predictions, certainties, targets, use_most_certain=True)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy()) # Shape (B, T)\n",
    "                            all_predictions_most_certain_list.append(these_predictions.argmax(1)[torch.arange(these_predictions.size(0), device=these_predictions.device), where_most_certain].detach().cpu().numpy()) # Shape (B,)\n",
    "\n",
    "                        elif args.model == 'ff':\n",
    "                            these_predictions = model(inputs)\n",
    "                            loss = nn.CrossEntropyLoss()(these_predictions, targets)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy()) # Shape (B,)\n",
    "\n",
    "                        all_losses.append(loss.item())\n",
    "\n",
    "                        if args.n_test_batches != -1 and inferi >= args.n_test_batches -1 : break # Check condition >= N-1\n",
    "                        pbar_inner.set_description(f'Computing metrics for train (Batch {inferi+1})')\n",
    "                        pbar_inner.update(1)\n",
    "\n",
    "                all_targets = np.concatenate(all_targets_list)\n",
    "                all_predictions = np.concatenate(all_predictions_list) # Shape (N, T) or (N,)\n",
    "                train_losses.append(np.mean(all_losses))\n",
    "\n",
    "                if args.model in ['ctm', 'lstm']:\n",
    "                    # Accuracies per tick for CTM/LSTM\n",
    "                    current_train_accuracies = np.mean(all_predictions == all_targets[...,np.newaxis], axis=0) # Mean over batch dim -> Shape (T,)\n",
    "                    train_accuracies.append(current_train_accuracies)\n",
    "                    # Most certain accuracy\n",
    "                    all_predictions_most_certain = np.concatenate(all_predictions_most_certain_list)\n",
    "                    current_train_accuracies_most_certain = (all_targets == all_predictions_most_certain).mean()\n",
    "                    train_accuracies_most_certain.append(current_train_accuracies_most_certain)\n",
    "                else: # FF\n",
    "                        current_train_accuracies = (all_targets == all_predictions).mean() # Shape scalar\n",
    "                        train_accuracies.append(current_train_accuracies)\n",
    "            \n",
    "            del these_predictions\n",
    "            \n",
    "\n",
    "            # Switch to eval mode for test metrics (fixed BN stats)\n",
    "            model.eval()\n",
    "            pbar.set_description('Tracking: Computing TEST metrics')\n",
    "            with torch.inference_mode(): # Use inference_mode for test eval\n",
    "                loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size_test, shuffle=True, num_workers=args.num_workers_test, collate_fn=kanji_collate_fn)\n",
    "                all_targets_list = []\n",
    "                all_predictions_list = []\n",
    "                all_predictions_most_certain_list = [] # Only for CTM/LSTM\n",
    "                all_losses = []\n",
    "\n",
    "                with tqdm(total=len(loader), initial=0, leave=False, position=1, dynamic_ncols=True) as pbar_inner:\n",
    "                    for inferi, (inputs, targets) in enumerate(loader):\n",
    "                        inputs = inputs.to(device)\n",
    "                        \n",
    "                        target_indices = [prompt_to_idx.get(prompt, 0) for prompt in targets]\n",
    "                        targets = torch.tensor(target_indices, dtype=torch.long).to(device)\n",
    "\n",
    "                        all_targets_list.append(targets.detach().cpu().numpy())\n",
    "\n",
    "                        # Model-specific forward and loss for evaluation\n",
    "                        if args.model == 'ctm':\n",
    "                            these_predictions, certainties, _ = model(inputs)\n",
    "                            loss, where_most_certain = loss_func(these_predictions, certainties, targets, use_most_certain=True)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy())\n",
    "                            all_predictions_most_certain_list.append(these_predictions.argmax(1)[torch.arange(these_predictions.size(0), device=these_predictions.device), where_most_certain].detach().cpu().numpy())\n",
    "\n",
    "                        elif args.model == 'lstm':\n",
    "                            these_predictions, certainties, _ = model(inputs)\n",
    "                            loss, where_most_certain = loss_func(these_predictions, certainties, targets, use_most_certain=True)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy())\n",
    "                            all_predictions_most_certain_list.append(these_predictions.argmax(1)[torch.arange(these_predictions.size(0), device=these_predictions.device), where_most_certain].detach().cpu().numpy())\n",
    "\n",
    "                        elif args.model == 'ff':\n",
    "                            these_predictions = model(inputs)\n",
    "                            loss = nn.CrossEntropyLoss()(these_predictions, targets)\n",
    "                            all_predictions_list.append(these_predictions.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "                        all_losses.append(loss.item())\n",
    "\n",
    "                        if args.n_test_batches != -1 and inferi >= args.n_test_batches -1: break\n",
    "                        pbar_inner.set_description(f'Computing metrics for test (Batch {inferi+1})')\n",
    "                        pbar_inner.update(1)\n",
    "\n",
    "                all_targets = np.concatenate(all_targets_list)\n",
    "                all_predictions = np.concatenate(all_predictions_list)\n",
    "                test_losses.append(np.mean(all_losses))\n",
    "\n",
    "                if args.model in ['ctm', 'lstm']:\n",
    "                    current_test_accuracies = np.mean(all_predictions == all_targets[...,np.newaxis], axis=0)\n",
    "                    test_accuracies.append(current_test_accuracies)\n",
    "                    all_predictions_most_certain = np.concatenate(all_predictions_most_certain_list)\n",
    "                    current_test_accuracies_most_certain = (all_targets == all_predictions_most_certain).mean()\n",
    "                    test_accuracies_most_certain.append(current_test_accuracies_most_certain)\n",
    "                else: # FF\n",
    "                        current_test_accuracies = (all_targets == all_predictions).mean()\n",
    "                        test_accuracies.append(current_test_accuracies)\n",
    "\n",
    "            # Plotting (conditional)\n",
    "            figacc = plt.figure(figsize=(10, 10))\n",
    "            axacc_train = figacc.add_subplot(211)\n",
    "            axacc_test = figacc.add_subplot(212)\n",
    "            cm = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "            if args.model in ['ctm', 'lstm']:\n",
    "                # Plot per-tick accuracy for CTM/LSTM\n",
    "                train_acc_arr = np.array(train_accuracies) # Shape (N_iters, T)\n",
    "                test_acc_arr = np.array(test_accuracies) # Shape (N_iters, T)\n",
    "                num_ticks = train_acc_arr.shape[1]\n",
    "                for ti in range(num_ticks):\n",
    "                        axacc_train.plot(iters, train_acc_arr[:, ti], color=cm(ti / num_ticks), alpha=0.3)\n",
    "                        axacc_test.plot(iters, test_acc_arr[:, ti], color=cm(ti / num_ticks), alpha=0.3)\n",
    "                # Plot most certain accuracy\n",
    "                axacc_train.plot(iters, train_accuracies_most_certain, 'k--', alpha=0.7, label='Most certain')\n",
    "                axacc_test.plot(iters, test_accuracies_most_certain, 'k--', alpha=0.7, label='Most certain')\n",
    "            else: # FF\n",
    "                axacc_train.plot(iters, train_accuracies, 'k-', alpha=0.7, label='Accuracy') # Simple line\n",
    "                axacc_test.plot(iters, test_accuracies, 'k-', alpha=0.7, label='Accuracy')\n",
    "\n",
    "            axacc_train.set_title('Train Accuracy')\n",
    "            axacc_test.set_title('Test Accuracy')\n",
    "            axacc_train.legend(loc='lower right')\n",
    "            axacc_test.legend(loc='lower right')\n",
    "            axacc_train.set_xlim([0, args.training_iterations])\n",
    "            axacc_test.set_xlim([0, args.training_iterations])\n",
    "            if args.dataset=='cifar10':\n",
    "                axacc_train.set_ylim([0.75, 1])\n",
    "                axacc_test.set_ylim([0.75, 1])\n",
    "\n",
    "\n",
    "\n",
    "            figacc.tight_layout()\n",
    "            figacc.savefig(f'{args.log_dir}/accuracies.png', dpi=150)\n",
    "            plt.close(figacc)\n",
    "\n",
    "            figloss = plt.figure(figsize=(10, 5))\n",
    "            axloss = figloss.add_subplot(111)\n",
    "            axloss.plot(iters, train_losses, 'b-', linewidth=1, alpha=0.8, label=f'Train: {train_losses[-1]:.4f}')\n",
    "            axloss.plot(iters, test_losses, 'r-', linewidth=1, alpha=0.8, label=f'Test: {test_losses[-1]:.4f}')\n",
    "            axloss.legend(loc='upper right')\n",
    "            axloss.set_xlim([0, args.training_iterations])\n",
    "            axloss.set_ylim(bottom=0)\n",
    "\n",
    "            figloss.tight_layout()\n",
    "            figloss.savefig(f'{args.log_dir}/losses.png', dpi=150)\n",
    "            plt.close(figloss)\n",
    "\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            model.train() # Switch back to train mode\n",
    "\n",
    "\n",
    "        # Save model checkpoint (conditional metrics)\n",
    "        if (bi % args.save_every == 0 or bi == args.training_iterations - 1) and bi != start_iter:\n",
    "            pbar.set_description('Saving model checkpoint...')\n",
    "            checkpoint_data = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'iteration': bi,\n",
    "                # Always save these\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'train_accuracies': train_accuracies, # This is list of scalars for FF, list of arrays for CTM/LSTM\n",
    "                'test_accuracies': test_accuracies, # This is list of scalars for FF, list of arrays for CTM/LSTM\n",
    "                'iters': iters,\n",
    "                'args': args, # Save args used for this run\n",
    "                'out_dims': args.out_dims,\n",
    "                'isGrayscale': args.isGrayscale,\n",
    "                # RNG states\n",
    "                'torch_rng_state': torch.get_rng_state(),\n",
    "                'numpy_rng_state': np.random.get_state(),\n",
    "                'random_rng_state': random.getstate(),\n",
    "            }\n",
    "            # Conditionally add metrics specific to CTM/LSTM\n",
    "            if args.model in ['ctm', 'lstm']:\n",
    "                checkpoint_data['train_accuracies_most_certain'] = train_accuracies_most_certain\n",
    "                checkpoint_data['test_accuracies_most_certain'] = test_accuracies_most_certain\n",
    "\n",
    "            torch.save(checkpoint_data, f'{args.log_dir}/checkpoint_{bi}.pt')\n",
    " \n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
